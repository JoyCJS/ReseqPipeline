##########4i24

#This is the bash pipeline Joy used for Tecan targeted resequencing analysis.
#For details/trial and error histories, please check Joy's Reseq48_Notes1.txt to Reseq48_Notes4.txt files.

#You can find example data here: /media/opt4/ExampleData.
#Create a new folder to store the fastq files.
mkdir FastqFiles
#Save files in the FastqFiles directory (for practicing/testing, copy 6 fastq files (3 paired-end samples) to the new FastqFiles directory).
cd FastqFiles/
gunzip *.gz

#Make a list of paired sample names so samples can be run using a while loop (or a for loop).
ls *.fastq | wc -l #This should print the number of fastq files.
ls *.fastq > a.txt
#Check file names, we want to list the files with shorter names.
#Example file names: "LBK22-A01_S1_L001_R1_001.fastq", "LBK22-A01_S1_L001_R2_001.fastq", "LBK22-A06_S41_L001_R1_001.fastq", and "LBK22-A06_S41_L001_R2_001.fastq".
#Example shortened paired sample names: "LBK22-A01_S1" and "LBK22-A06_S41".
sed -i 's/_L001_R1_001.fastq//g' a.txt #Modify this part based on your file names.
sed -i 's/_L001_R2_001.fastq//g' a.txt #Same here.
sort a.txt | uniq > names.txt
wc names.txt #This should print the number of samples (half of the number of fastq files).
rm a.txt

#Create a new folder for analysis.
mkdir GATK
mv names.txt GATK/

#The reference sequence we're using is Ref7755, an artificial reference of 7,755 sequences (used as chromosomes; including 2,770 targets and 4,985 corresponding paralogs/homoeologs).
#Copy the Ref7755 reference and other required files here.
cd GATK/
cp /media/_opt3/Resequencing/48SamplesData/GATK/Ref7755/Ref7755.* .
ls -ltra #Use this command to check what's in the folder regularly.
#There should be 9 files (names.txt, Ref7755.dict, Ref7755.fna, Ref7755.fna.amb, Ref7755.fna.ann, Ref7755.fna.bwt, Ref7755.fna.fai, Ref7755.fna.pac, and Ref7755.fna.sa).

#If you're using Ref7755 as your reference, then skip this step below, because you have copied all you need.
#If you want to use a different reference, follow this session to reference bwa, create file index, and generate sequence dictionary.
bwa index -a bwtsw Reference.fna
samtools faidx Reference.fna
mv Reference.fna Reference.fasta
java -jar /opt/picardtools/picard-tools-1.98/CreateSequenceDictionary.jar REFERENCE=Reference.fasta OUTPUT=Reference.dict
mv Reference.fasta Reference.fna
#If you're using a different reference, some codes might need to be modified for the rest of steps.

#Run bwa; remember to modify this part based on your file names.
nohup bash -c 'while read A; do bwa aln -t 12 Ref7755.fna ../"$A"_L001_R1_001.fastq > $A.1.bwa; done < names.txt' &
#Remember to write down your nohup job number each time you run with nohup, in case you want to stop it.
#Always check nohup.out file after it's completed, if there's no error, remove it (or rename it if there's any information you want to keep).
rm nohup.out
nohup bash -c 'while read A; do bwa aln -t 12 Ref7755.fna ../"$A"_L001_R2_001.fastq > $A.2.bwa; done < names.txt' &
rm nohup.out
ls *.bwa | wc -l #This should print the number of fastq files.

#Run sampe; remember to modify this part based on your file names.
nohup bash -c 'while read A; do bwa sampe Ref7755.fna $A.1.bwa $A.2.bwa ../"$A"_L001_R1_001.fastq ../"$A"_L001_R2_001.fastq > $A.sam; done < names.txt' &
#This could take some minutes.
rm nohup.out
ls *.sam | wc -l #This should print the number of samples.

#Run bam files.
nohup bash -c 'while read A; do samtools view -F 4 -Sbh $A.sam > $A.bam; done < names.txt' &
#This could take some minutes.
rm nohup.out
ls *.bam | wc -l #This should print the number of samples.

#If you don't have a file including the information below, check this session.
#Extract RGPU (barcodes) to make a new list; remember to modify this part based on your file names.
nohup bash -c 'while read A; do head -1 ../"$A"_L001_R1_001.fastq >> Heads.txt; done < names.txt' &
rm nohup.out
awk '{print $2}' Heads.txt > Barcode.txt #Check whether modification is needed.
sed -i 's/1:N:0://g' Barcode.txt  #Check whether modification is needed.
paste names.txt Barcode.txt > a.txt
#Use "vi" then type "i" to edit the file by adding the 2nd and the 3rd columns manually (see example below).
vi a.txt
#You just need to fill in the 2nd and the 3rd columns, no need to sort them for now, we'll do it later.
#Eventually you'll want to have them sorted in the same order as the original sample numbers.
#Here's an example (tab delimited) with 4 columns: names, numbers, samples, RGPU (barcodes):
LBK22-B01_S2     37     sample37     AATCCAGC
LBK22-A01_S1     43     sample43     CGCTACAT
LBK22-A06_S41    48     sample48     ACGCTTCT
#After editing the file, press "esc", then type ":wq!" to save (use ":q!" if you don't want to save it).
#You can always look at your file with "less" command.
less a.txt #Type "q" to exit.
#Here are some other useful tips while viewing data with "less":
#Type "g" to the top of the file, type "G" to the bottom of the file (if the file is gigantic, it could take a long time to go to the bottom, then you can press "Ctrl+C" to abort it).
#Type "-N" to show line numbers (if the file is gigantic, it could take a long time to complete this job), type "-N" again to hide line numbers.
#Sort it by the sample numbers (the 2nd column).
sort -k2n a.txt > Names.txt
wc Names.txt #This should print the number of samples.
rm Heads.txt Barcode.txt a.txt
#Make sure all the information and format are correct in the "Names.txt" before proceeding to the next step.

#Run picardtools.
nohup bash -c 'while read A B C D; do java -jar /opt/picardtools/picard-tools-1.98/AddOrReplaceReadGroups.jar I=$A.bam O=$A.RG.bam RGID=$B RGLB=$C RGPL=illumina RGPU=$D RGSM=$C SORT_ORDER=coordinate CREATE_INDEX=true; done < Names.txt' &
#This could take some minutes.
ls *.bam | wc -l #This should print the number of fastq files.
ls *.bai | wc -l #This should print the number of samples.
grep "Alignment start should != 0 because reference name != *" nohup.out #Just to make sure that there's no problem.
rm nohup.out
awk '{print $1}' Names.txt > NamesPE.txt

#SortSam.
nohup bash -c 'while read A; do java -jar /opt/picardtools/picard-tools-1.98/SortSam.jar I=$A.RG.bam O=$A.RG.sorted.bam SORT_ORDER=coordinate; done < NamesPE.txt' &
#This could take some minutes.
rm nohup.out
nohup bash -c 'while read A; do java -jar /opt/picardtools/picard-tools-1.98/MarkDuplicates.jar I=$A.RG.sorted.bam O=$A.RG.sorted.dedup.bam M=$A.RG.sorted.bam.metrics MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1000; done < NamesPE.txt' &
#This could take some minutes.
rm nohup.out
nohup bash -c 'while read A; do java -jar /opt/picardtools/picard-tools-1.98/BuildBamIndex.jar I=$A.RG.sorted.dedup.bam; done < NamesPE.txt' &
#This could take some minutes.
rm nohup.out

#Run GATK.
#I skipped the step of making sam files and just run GATK directly (if you want to make thoses sam files, check PSS6424 Lab10 handout for the "samtools view" steps).
#Run GATK with parameter for 0/0 (reference confidence); For more information, please check the GATK Guidebook in the Blackserver (Page 379/400).
#Also check this paper "Computational Exome and Genome Analysis" by Peter N. Robinson, Rosario Michael Piro, and Marten Jager (2017) published at CRC Press (Chapter 13.10, Page 199).
nohup bash -c 'while read A; do java -jar /opt/GenomeAnalysisTK/GenomeAnalysisTK.jar -R Ref7755.fna -T HaplotypeCaller -variant_index_type LINEAR -variant_index_parameter 128000 --emitRefConfidence GVCF -I $A.RG.sorted.dedup.bam -stand_call_conf 20 -stand_emit_conf 20 --allow_potentially_misencoded_quality_scores -o $A.RG.raw.snps.indels.vcf; done < NamesPE.txt' &
#Time varies but it took almost one day to finish running 48 samples.
ls *.vcf | wc -l #This should print the number of samples.
ls *.vcf.idx | wc -l #This should print the number of samples.
mv nohup.out nohup.7755out.txt #Save as record.

#Identification of SNPs among samples by Haplotype Caller.
nohup bash -c 'while read A; do /opt/tabix/bgzip $A.RG.raw.snps.indels.vcf; done < NamesPE.txt' &
rm nohup.out
nohup bash -c 'while read A; do /opt/tabix/tabix $A.RG.raw.snps.indels.vcf.gz; done < NamesPE.txt' &
rm nohup.out
ls *.vcf.gz | wc -l #This should print the number of samples.
ls *.vcf.gz.tbi | wc -l #This should print the number of samples.

#Vcf merge.
export PERL5LIB=/opt/vcftools/vcftools_0.1.11/perl
export PATH=$PATH:/opt/tabix/
ls *.RG.raw.snps.indels.vcf.gz | wc -l #This should print the number of samples.
nohup bash -c 'vcf-merge *.RG.raw.snps.indels.vcf.gz | /opt/tabix/bgzip -c > pooledHC.vcf.gz' &
#Time varies but it took around 8 hours to finish running 48 samples.
#Nohup should show something like this:
#The version "4.2" not supported, assuming VCFv4.1
#Using column name 'sample43' for LBK22-A01_S1.RG.raw.snps.indels.vcf.gz:sample43
mv nohup.out nohup.SampleNames.txt #Save as record.

#Unzip the pooled vcf file.
gunzip pooledHC.vcf.gz
#Remember that, not all these SNPs are the targets; your targeted SNPs are the 151st positions on the target sequences only.
#You can check it with "less" command.
less pooledHC.vcf
#Instead of scrolling down, try directly type a number (let's type "8000" then hit "enter", it'll bring you to 8000 lines below where you were at).
#Type "q" to exit.
#Notice that the "GT:DP:GQ:MIN_DP:PL" (single vcf) now becomes "GT:GQ:DP:MIN_DP:PL" and some other different forms/orders (pooled vcf).
#You can filter this dataset using other methods, or use the method that I used below.

#Filter by GQ and DP (typically GQ < 30 and DP < 10, or with loose threshold GQ < 6 and DP < 2).
#I followed the steps from the bottom of this webpage: https://evodify.com/gatk-in-non-model-organism/.
java -jar /opt/GenomeAnalysisTK/GenomeAnalysisTK.jar -T VariantFiltration -R Ref7755.fna -V pooledHC.vcf -G_filter "GQ < 30 || DP < 10" -G_filterName "Filtered" -o FilteredStep1.vcf
java -jar /opt/GenomeAnalysisTK/GenomeAnalysisTK.jar -T SelectVariants -R Ref7755.fna -V FilteredStep1.vcf --setFilteredGtToNocall -o FilteredStep2.vcf
java -Xmx8g -jar /opt/GenomeAnalysisTK/GenomeAnalysisTK.jar -T VariantsToTable -R Ref7755.fna -V FilteredStep2.vcf -F CHROM -F POS -GF GT -o FilteredFinalVCF.table

#Copy the list of information of 2,770 targets to the folder.
cp /media/_opt3/Resequencing/48SamplesData/2770TargetInfo.txt .

#Extract reference genotype.
cat -n pooledHC.vcf | awk '$2 == "#CHROM"' | awk '{print $1}' > StartNum.txt
for i in $(cat StartNum.txt); do tail -n +$((i)) pooledHC.vcf > CleanVCF.txt; done
awk '{print $4}' CleanVCF.txt > RefGT.txt
paste RefGT.txt FilteredFinalVCF.table > GtVcf.txt
rm StartNum.txt CleanVCF.txt RefGT.txt
#Extract data only for SNPs at the targeted 151st positions.
awk '$3 == "151"' GtVcf.txt > Pos151.txt
grep Target Pos151.txt > Pos151Target.txt
#Collect information for the SNPs.
sed -i 's/_Target//g' Pos151Target.txt
awk '{print $2}' Pos151Target.txt > List.txt
while read A; do grep -w "$A" 2770TargetInfo.txt >> ListInfo.txt; done < List.txt
cut -f 2,3 --complement Pos151Target.txt > Genotype.txt
wc -l ListInfo.txt Genotype.txt #Their numbers of lines should be the same.
paste ListInfo.txt Genotype.txt > a.txt
#Add headers and output results.
head -1 2770TargetInfo.txt > Header1.txt
head -1 GtVcf.txt | cut -f 2,3 --complement > Header2.txt
paste Header1.txt Header2.txt > Headers.txt
cat Headers.txt a.txt > Results.txt
rm Pos151.txt List.txt Pos151Target.txt ListInfo.txt Genotype.txt GtVcf.txt a.txt Header*

#The Results.txt should look like this:
#Target   Ref   Chr   Pos       REF   sample37.GT sample43.GT sample48.GT
#M_802    Tif1  A02   96307368   G       G/G         A/A         G/G
#M_2987   Tif1  A08   5056232    A       G/G         A/A          .
#M_7795   Tif1  B10   43563936   T       T/T         C/C         T/T
#RA_332   Tif2  A10   6375783    G       ./.         G/T         G/G
#RB_62    Tif2  B03   14730070   T       T/G         T/G         T/G
#Genotype "." means missing data, and "./." means low quality (filtered out).

#Download the Results.txt file to PC and open in excel.
#Replace the sample numbers with accession names for further analysis (for example: sample37=TxAG-6, sample43=43-09-03-02, and sample48=Tifrunner).

##########Welcome to contact Joy Sung (cjsung0130@gmail.com) if you have any question.
